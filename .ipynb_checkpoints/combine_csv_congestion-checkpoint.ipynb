{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data\\congestion_data')         #set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\feron\\\\TIL6022---Project\\\\data\\\\congestion_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd                                      #check working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 6C71-ECE1\n",
      "\n",
      " Directory of C:\\Users\\feron\\TIL6022---Project\\data\\congestion_data\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\feron\\TIL6022---Project\\data\\congestion_data\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\feron\\TIL6022---Project\\data\\congestion_data\n",
      "\n",
      "\n",
      " Directory of C:\\Users\\feron\\TIL6022---Project\\data\\congestion_data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n"
     ]
    }
   ],
   "source": [
    "ls                                       #see files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension = '.csv'\n",
    "all_filenames = [i for i in glob.glob(f\"*{file_extension}\")]\n",
    "#use global to find all filenames in the directory with the extension .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-03.csv', '2020-04.csv', '2020-05.csv', '2020-06.csv', '2020-07.csv', '2020-08.csv', '2020-09.csv', '2020-10.csv', '2020-11.csv', '2020-12.csv', '2021-01.csv', '2021-02.csv', '2021-03.csv', '2021-04.csv', '2021-05.csv', '2021-06.csv', '2021-07.csv', '2021-08.csv', '2021-09.csv', '2021-10.csv', '2021-11.csv', '2021-12.csv', '2022-01.csv', '2022-02.csv', '2022-03.csv', '2022-04.csv', '2022-05.csv', '2022-06.csv', '2022-07.csv', '2022-08.csv', '2022-09.csv']\n"
     ]
    }
   ],
   "source": [
    "print(all_filenames)\n",
    "#shows all the filenames, check if all files are mentioned in the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_filenames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.7525, 'language': ''}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "with open(a, 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result\n",
    "#this cell check wich encoding is used for the data from RWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(a,                                                 #filename\n",
    "                 encoding='utf-8',                                  #type of encoding used for our data\n",
    "                 delimiter=';',                                     #how the data is seperated\n",
    "                 parse_dates=[['DatumFileBegin', 'TijdFileBegin']], #make dates from the data\n",
    "                 index_col='DatumFileBegin_TijdFileBegin')          #the index column is the date and time of the congestion\n",
    "\n",
    "#This cell is used to know how I want the dataframe to be made\n",
    "#I will apply this code to the loop to combine all csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_data = pd.concat([pd.read_csv(f, delimiter=';', parse_dates=[['DatumFileBegin', 'TijdFileBegin']],\n",
    "                 index_col='DatumFileBegin_TijdFileBegin') for f in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269325, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_data.shape  #check if all data is combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
